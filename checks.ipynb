{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333a8dbf-6278-4018-bd56-906232837995",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8c6bc29-9c95-47b9-8b32-f3095c384c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad4c10f0-01ae-4bc9-b2ff-a209ed06ee9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"\"\"\n",
    "You are a painting instructor for students.\n",
    "Assume your students are using a simple mspaint-like image editor.\n",
    "They want to learn how to draw a basic black sketch of <item>orange</item>.\n",
    "To be more practical, you need to create a 4 steps tutorial.\n",
    "Each step need to have a JSON formatted description with a title, 2 sentence instruction, 5 sentence extended instruction, and a few general tips.\n",
    "Write the tutorial without preambles.\n",
    "\"\"\"\n",
    "            }\n",
    "        ]\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    input=history,\n",
    "    store=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c9c8bce-02a4-4f72-be3d-14859ef75ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"tutorial\": [\n",
      "    {\n",
      "      \"title\": \"Step 1: Outline the Shape\",\n",
      "      \"instruction\": \"Start by drawing a simple circle for the body of the orange. Keep the shape round and smooth.\",\n",
      "      \"extended_instruction\": \"Use the circle tool or freehand method to create a circular shape. Ensure the circle is not too perfect; a slight irregularity will make it look more natural. Don't worry about detailing yet; focus solely on getting the basic form down. You can use light strokes, so you can adjust them easily later. Once you are satisfied, you can proceed to the next step.\",\n",
      "      \"tips\": [\n",
      "        \"Use the grid feature if available to help maintain proportion.\",\n",
      "        \"If drawing freehand, practice a few circles on a separate canvas first.\",\n",
      "        \"Adjust the size according to your canvas space.\",\n",
      "        \"Don't press too hard with your cursor; light strokes are easier to erase.\",\n",
      "        \"You can sketch a rough outline and refine it later.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Step 2: Add the Dimple\",\n",
      "      \"instruction\": \"Draw a small indentation at the top of the circle to represent the dimple where the stem attaches. This will give your orange a more realistic appearance.\",\n",
      "      \"extended_instruction\": \"Using a smaller brush, create a small oval shape at the top center of the circle. This oval should be slightly deeper into the circle than the outer line. Remember to keep the dimple proportional to the size of the orange; it should not be overly large. You can make multiple small strokes to shape it until you find the right look. If necessary, erase and refine until it fits well with the overall shape.\",\n",
      "      \"tips\": [\n",
      "        \"Use the undo function effectively if you make errors.\",\n",
      "        \"Keep the oval shape smaller than a quarter of the circle's diameter.\",\n",
      "        \"Experiment with different brush sizes for best results.\",\n",
      "        \"Don't rush; take your time to achieve a smooth outline.\",\n",
      "        \"Consider the direction of light when shading later.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Step 3: Sketch the Leaves\",\n",
      "      \"instruction\": \"Draw two leaves at the top of the dimple to enhance the look of the orange. Make sure one leaf is slightly bigger than the other for a natural feel.\",\n",
      "      \"extended_instruction\": \"Use the curved line tool or freehand sketch to create two leaf shapes. They can be elongated ovals with pointed tips to represent orange leaves accurately. Position one leaf slightly behind the other to add depth and dimension. Remember to tilt them slightly to make them appear more dynamic. Once you’re happy with the shapes, finalize their outlines.\",\n",
      "      \"tips\": [\n",
      "        \"Utilize light strokes to draft the leaves before finalizing the shape.\",\n",
      "        \"Observe real orange leaves for better reference on shape and orientation.\",\n",
      "        \"Consider the angle of the leaves relative to the orange.\",\n",
      "        \"Leaves should be smaller in size compared to the orange.\",\n",
      "        \"Use colors later to differentiate the leaves from the orange.\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"title\": \"Step 4: Final Touches\",\n",
      "      \"instruction\": \"Go over your sketch with a black line to give it more definition. Erase any unnecessary marks to clean up the drawing.\",\n",
      "      \"extended_instruction\": \"Using a thicker brush, carefully trace over the outlines of your orange, dimple, and leaves. This will enhance the overall visibility and give your sketch a finished look. After outlining, step back and see if there are any areas that need adjusting or refining. Erase any stray lines or rough edges to make your sketch clean. If desired, you can fill in with shadows or highlights later for depth.\",\n",
      "      \"tips\": [\n",
      "        \"Take breaks to view your sketch with fresh eyes.\",\n",
      "        \"Be gentle while erasing so you don’t smudge your work.\",\n",
      "        \"Consider using different line thicknesses for added interest.\",\n",
      "        \"Don't hesitate to redo areas that don’t look right.\",\n",
      "        \"Practice will make your lines smoother over time.\"\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a074f354-a796-4c44-9076-8510c2064fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"tutorial\": [\\n    {\\n      \"title\": \"Step 1: Outline the Shape\",\\n      \"instruction\": \"Start by drawing a simple circle for the body of the orange. Keep the shape round and smooth.\",\\n      \"extended_instruction\": \"Use the circle tool or freehand method to create a circular shape. Ensure the circle is not too perfect; a slight irregularity will make it look more natural. Don\\'t worry about detailing yet; focus solely on getting the basic form down. You can use light strokes, so you can adjust them easily later. Once you are satisfied, you can proceed to the next step.\",\\n      \"tips\": [\\n        \"Use the grid feature if available to help maintain proportion.\",\\n        \"If drawing freehand, practice a few circles on a separate canvas first.\",\\n        \"Adjust the size according to your canvas space.\",\\n        \"Don\\'t press too hard with your cursor; light strokes are easier to erase.\",\\n        \"You can sketch a rough outline and refine it later.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Step 2: Add the Dimple\",\\n      \"instruction\": \"Draw a small indentation at the top of the circle to represent the dimple where the stem attaches. This will give your orange a more realistic appearance.\",\\n      \"extended_instruction\": \"Using a smaller brush, create a small oval shape at the top center of the circle. This oval should be slightly deeper into the circle than the outer line. Remember to keep the dimple proportional to the size of the orange; it should not be overly large. You can make multiple small strokes to shape it until you find the right look. If necessary, erase and refine until it fits well with the overall shape.\",\\n      \"tips\": [\\n        \"Use the undo function effectively if you make errors.\",\\n        \"Keep the oval shape smaller than a quarter of the circle\\'s diameter.\",\\n        \"Experiment with different brush sizes for best results.\",\\n        \"Don\\'t rush; take your time to achieve a smooth outline.\",\\n        \"Consider the direction of light when shading later.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Step 3: Sketch the Leaves\",\\n      \"instruction\": \"Draw two leaves at the top of the dimple to enhance the look of the orange. Make sure one leaf is slightly bigger than the other for a natural feel.\",\\n      \"extended_instruction\": \"Use the curved line tool or freehand sketch to create two leaf shapes. They can be elongated ovals with pointed tips to represent orange leaves accurately. Position one leaf slightly behind the other to add depth and dimension. Remember to tilt them slightly to make them appear more dynamic. Once you’re happy with the shapes, finalize their outlines.\",\\n      \"tips\": [\\n        \"Utilize light strokes to draft the leaves before finalizing the shape.\",\\n        \"Observe real orange leaves for better reference on shape and orientation.\",\\n        \"Consider the angle of the leaves relative to the orange.\",\\n        \"Leaves should be smaller in size compared to the orange.\",\\n        \"Use colors later to differentiate the leaves from the orange.\"\\n      ]\\n    },\\n    {\\n      \"title\": \"Step 4: Final Touches\",\\n      \"instruction\": \"Go over your sketch with a black line to give it more definition. Erase any unnecessary marks to clean up the drawing.\",\\n      \"extended_instruction\": \"Using a thicker brush, carefully trace over the outlines of your orange, dimple, and leaves. This will enhance the overall visibility and give your sketch a finished look. After outlining, step back and see if there are any areas that need adjusting or refining. Erase any stray lines or rough edges to make your sketch clean. If desired, you can fill in with shadows or highlights later for depth.\",\\n      \"tips\": [\\n        \"Take breaks to view your sketch with fresh eyes.\",\\n        \"Be gentle while erasing so you don’t smudge your work.\",\\n        \"Consider using different line thicknesses for added interest.\",\\n        \"Don\\'t hesitate to redo areas that don’t look right.\",\\n        \"Practice will make your lines smoother over time.\"\\n      ]\\n    }\\n  ]\\n}\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09640c63-cf05-4d27-a8f5-a28541dd222c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate an image for each step in sketching an orange.\n",
      "Each image should be 500x500px with a white background, contain the example sketch and nothing else.\n",
      "Each image should have few easy additional strokes relative to the previous step and image.\n",
      "The images should be generated together in a 2x2 grid with the steps ordered from left to right and from up to bottom.\n",
      "The steps are:\n",
      " - Start by drawing a simple circle for the body of the orange. Keep the shape round and smooth.\n",
      " - Draw a small indentation at the top of the circle to represent the dimple where the stem attaches. This will give your orange a more realistic appearance.\n",
      " - Draw two leaves at the top of the dimple to enhance the look of the orange. Make sure one leaf is slightly bigger than the other for a natural feel.\n",
      " - Go over your sketch with a black line to give it more definition. Erase any unnecessary marks to clean up the drawing.\n"
     ]
    }
   ],
   "source": [
    "image_prompt = \"\"\"Generate an image for each step in sketching {{objective}}.\n",
    "Each image should be 500x500px with a white background, contain the example sketch and nothing else.\n",
    "Each image should have few easy additional strokes relative to the previous step and image.\n",
    "The images should be generated together in a 2x2 grid with the steps ordered from left to right and from up to bottom.\n",
    "The steps are:\n",
    "\"\"\".replace(\"{{objective}}\",\"an orange\") + \" - \" + \"\\n - \".join(\n",
    "    [el[\"instruction\"] for el in json.loads(response.output_text.strip('```json'))['tutorial']]\n",
    ")\n",
    "print(image_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec5c9557-208a-4045-b2fa-a827863071f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_response2 = client.images.generate(\n",
    "    prompt = image_prompt,\n",
    "    # background = \"white\",\n",
    "    model = 'dall-e-2', # model= 'gpt-image-1',\n",
    "    \n",
    "    # moderation: \"Optional[Literal['low', 'auto']] | NotGiven\" = NOT_GIVEN,\n",
    "    n=1,\n",
    "    # output_format= \"jpeg\",\n",
    "    # quality='standard',\n",
    "    # response_format='b64_json',\n",
    "    size='256x256',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "11b204ac-a7e0-4ff4-95df-56930a08e89c",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionDeniedError",
     "evalue": "Error code: 403 - {'error': {'message': 'Your organization must be verified to use the model `gpt-image-1`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionDeniedError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m image_response_new = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# background = \"white\",\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpt-image-1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# moderation: \"Optional[Literal['low', 'auto']] | NotGiven\" = NOT_GIVEN,\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# output_format= \"jpeg\",\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlow\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# response_format='b64_json',\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1024x1024\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/resources/images.py:322\u001b[39m, in \u001b[36mImages.generate\u001b[39m\u001b[34m(self, prompt, background, model, moderation, n, output_compression, output_format, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\n\u001b[32m    229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    230\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    251\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    252\u001b[39m ) -> ImagesResponse:\n\u001b[32m    253\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[33;03m    [Learn more](https://platform.openai.com/docs/guides/images).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/images/generations\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmoderation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoderation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_compression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquality\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstyle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstyle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m            \u001b[49m\u001b[43mimage_generate_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mImageGenerateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mImagesResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mPermissionDeniedError\u001b[39m: Error code: 403 - {'error': {'message': 'Your organization must be verified to use the model `gpt-image-1`. Please go to: https://platform.openai.com/settings/organization/general and click on Verify Organization. If you just verified, it can take up to 15 minutes for access to propagate.', 'type': 'invalid_request_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "image_response_new = client.images.generate(\n",
    "    prompt = image_prompt,\n",
    "    # background = \"white\",\n",
    "    model ='gpt-image-1',\n",
    "    \n",
    "    # moderation: \"Optional[Literal['low', 'auto']] | NotGiven\" = NOT_GIVEN,\n",
    "    n=1,\n",
    "    # output_format= \"jpeg\",\n",
    "    quality='low',\n",
    "    # response_format='b64_json',\n",
    "    size='1024x1024',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea06f662-7a14-4cac-90a3-8fbc01457d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_response = client.images.generate(\n",
    "    prompt = image_prompt,\n",
    "    # background = \"white\",\n",
    "    model = 'dall-e-3', # model= 'gpt-image-1',\n",
    "    \n",
    "    # moderation: \"Optional[Literal['low', 'auto']] | NotGiven\" = NOT_GIVEN,\n",
    "    n=1,\n",
    "    # output_format= \"jpeg\",\n",
    "    # quality='standard',\n",
    "    # response_format='b64_json',\n",
    "    size='1024x1024',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a125e17-4b70-4a4b-be98-131ae688cdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImagesResponse(created=1747559444, data=[Image(b64_json=None, revised_prompt=None, url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-jhnHVZF472ujXli291chsg1w/user-Tuspo1vDgdaqLqAozP1DgA3N/img-7AuyP6eb8aQaTLMXJ8LrQj4G.png?st=2025-05-18T08%3A10%3A44Z&se=2025-05-18T10%3A10%3A44Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-17T21%3A53%3A13Z&ske=2025-05-18T21%3A53%3A13Z&sks=b&skv=2024-08-04&sig=yxtya88BApm6DWvsth0g/gQok35HxTnalQGGemW3xfs%3D')], usage=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_response2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0812fe71-474a-4237-a259-7c032a5e732b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImagesResponse(created=1747559349, data=[Image(b64_json=None, revised_prompt='Generate a 2x2 grid of 500x500px images each teaching the sketching process of an orange on a white background. Each image should add few strokes to its predecessor. Image 1: A basic, circular outline representing the body of the orange. Image 2: The same circle but with an added small indentation at the top representing the spot where the stem attaches. Image 3: Add two leaves in relation to the indent, ensuring one leaf is slightly larger than the other. Image 4: The final illustration should be a refined sketch, excess marks erased, and embodied with a defining black line sketch.', url='https://oaidalleapiprodscus.blob.core.windows.net/private/org-jhnHVZF472ujXli291chsg1w/user-Tuspo1vDgdaqLqAozP1DgA3N/img-CPEl2Q0Loj9X4zJM3RbWBH7z.png?st=2025-05-18T08%3A09%3A09Z&se=2025-05-18T10%3A09%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-17T21%3A29%3A56Z&ske=2025-05-18T21%3A29%3A56Z&sks=b&skv=2024-08-04&sig=QRM9X4YPBimVk68wZGbRtn1UEXdTk8j254qnsAsL660%3D')], usage=None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc9b3017-39ee-451a-83ca-aef640c46737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Generate a grid of 4 images that show the tutorial steps for sketching {{objective}} using tools like mspaint: \n",
    "# \"\"\".replace(\"{{objective}}\",\"an orange\") +\"\\n\".join([el[\"instruction\"] for el in json.loads(response.output_text.strip('```json'))['tutorial']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2097ffed-99c9-4a0c-881a-1591238d20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chatdraw.ready_tutorials.tutorial_creator import create_tutorial_for_item_sketching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbb6d817-75cb-41b6-8f01-674abed73ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = create_tutorial_for_item_sketching(\"watermelon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c0e0aa-9e9b-484e-8a28-31b3c1abe9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'assistant',\n",
       " 'content': [ResponseOutputText(annotations=[], text=\"I'm unable to create images directly, but I can certainly guide you on how to create them for each step using a simple image editor. Here’s how:\\n\\n1. **Step 1 - Sketch the Outline:**\\n   - Draw a large oval shape centered in the canvas.\\n   - Ensure the ends are slightly pointed and the middle is wider.\\n\\n2. **Step 2 - Add Seed Shapes:**\\n   - Using the previous oval as a base, add small teardrop shapes scattered inside the oval to represent seeds.\\n\\n3. **Step 3 - Create Texture Lines:**\\n   - Add curved lines radiating from the ends of the oval to simulate the texture of a watermelon rind.\\n\\n4. **Step 4 - Final Touches:**\\n   - Darken the outer outline of the oval and refine any edges.\\n   - Optionally, add light shading on one side for dimension.\\n\\n### Instructions for a 2x2 Grid\\n\\n- **Grid Layout:**\\n  - Create a new 1000x1000 px canvas (2x2 images at 500x500).\\n  \\n- **Positioning:**\\n  - Place the first step in the top-left (0,0), second step in the top-right (500,0), third step in the bottom-left (0,500), and fourth step in the bottom-right (500,500).\\n\\n### Tool Recommendations:\\n- Use Microsoft Paint or any other basic image editing tool.\\n- Adjust the brush size as needed for different details.\\n- Save each step individually and then compile them into a single image if needed.\\n\\nIf you need any further specific instructions or help with the tools, feel free to ask!\", type='output_text')]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c80f18-52d7-4db1-888a-aff11469e813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "create_tutorial_for_item_sketching(\n",
       "    item,\n",
       "    tutorial_template=[\u001b[33m'\\nYou are a painting instructor for students.\\nAssume your students are using a simple mspaint-like image editor.\\nThey want to learn how to draw a basic black sketch of <item>{{objective}}</item>.\\nTo be more practical, you need to create a 4 steps tutorial.\\nEach step need to have a JSON formatted description with a title, 2 sentence instruction, 5 sentence extended instruction, and a few general tips.\\nWrite the tutorial without preambles.\\n'\u001b[39m, \u001b[33m'\\ngenerate an image for each step.\\nEach image should be 500x500px with a white background, contain the example sketch and nothing else.\\nEach image should have few easy additional strokes relative to the previous step and image.\\nThe images should be generated together in a 2x2 grid with the steps ordered from left to right and from up to bottom.\\n'\u001b[39m, \u001b[33m'\\nCorrect the JSON tutorial to better fit the generated images. Write without preambles. \\n'\u001b[39m],\n",
       "    verbose=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       ")\n",
       "\u001b[31mDocstring:\u001b[39m <no docstring>\n",
       "\u001b[31mSource:\u001b[39m   \n",
       "\u001b[38;5;28;01mdef\u001b[39;00m create_tutorial_for_item_sketching(item,tutorial_template=PROMPT_TUTORIAL_CREATION_TEMPLATE,verbose=\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
       "    client = OpenAI()\n",
       "    history = []\n",
       "    \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;28;01min\u001b[39;00m tutorial_template:\n",
       "        prompt = prompt.replace(\u001b[33m\"{{objective}}\"\u001b[39m,item)\n",
       "        history += [\n",
       "            {\n",
       "                \u001b[33m\"role\"\u001b[39m: \u001b[33m\"user\"\u001b[39m,\n",
       "                \u001b[33m\"content\"\u001b[39m: prompt\n",
       "            }\n",
       "        ]\n",
       "\n",
       "        response = client.responses.create(\n",
       "            model= \u001b[33m\"gpt-image-1\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prompt.startswith(\u001b[33m\"generate an image\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"gpt-4o-mini\"\u001b[39m,\n",
       "            input=history,\n",
       "            store=\u001b[38;5;28;01mFalse\u001b[39;00m,\n",
       "        )\n",
       "        \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
       "            print(response.output_text)\n",
       "\n",
       "        \u001b[38;5;66;03m# Add the response to the conversation\u001b[39;00m\n",
       "        history += [{\u001b[33m\"role\"\u001b[39m: el.role, \u001b[33m\"content\"\u001b[39m: el.content} \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;28;01min\u001b[39;00m response.output]\n",
       "    \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
       "\u001b[31mFile:\u001b[39m      ~/exercises/chatdraw/chatdraw/ready_tutorials/tutorial_creator.py\n",
       "\u001b[31mType:\u001b[39m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_tutorial_for_item_sketching??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50f37a41-24e7-4724-9d69-3a72ad14db5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[31mSignature:\u001b[39m\n",
       "client.images.generate(\n",
       "    *,\n",
       "    prompt: \u001b[33m'str'\u001b[39m,\n",
       "    background: \u001b[33m\"Optional[Literal['transparent', 'opaque', 'auto']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    model: \u001b[33m'Union[str, ImageModel, None] | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    moderation: \u001b[33m\"Optional[Literal['low', 'auto']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    n: \u001b[33m'Optional[int] | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    output_compression: \u001b[33m'Optional[int] | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    output_format: \u001b[33m\"Optional[Literal['png', 'jpeg', 'webp']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    quality: \u001b[33m\"Optional[Literal['standard', 'hd', 'low', 'medium', 'high', 'auto']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    response_format: \u001b[33m\"Optional[Literal['url', 'b64_json']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    size: \u001b[33m\"Optional[Literal['auto', '1024x1024', '1536x1024', '1024x1536', '256x256', '512x512', '1792x1024', '1024x1792']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    style: \u001b[33m\"Optional[Literal['vivid', 'natural']] | NotGiven\"\u001b[39m = NOT_GIVEN,\n",
       "    user: \u001b[33m'str | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       "    extra_headers: \u001b[33m'Headers | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    extra_query: \u001b[33m'Query | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    extra_body: \u001b[33m'Body | None'\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
       "    timeout: \u001b[33m'float | httpx.Timeout | None | NotGiven'\u001b[39m = NOT_GIVEN,\n",
       ") -> \u001b[33m'ImagesResponse'\u001b[39m\n",
       "\u001b[31mDocstring:\u001b[39m\n",
       "Creates an image given a prompt.\n",
       "[Learn more](https://platform.openai.com/docs/guides/images).\n",
       "\n",
       "Args:\n",
       "  prompt: A text description of the desired image(s). The maximum length is 32000\n",
       "      characters for `gpt-image-1`, 1000 characters for `dall-e-2` and 4000 characters\n",
       "      for `dall-e-3`.\n",
       "\n",
       "  background: Allows to set transparency for the background of the generated image(s). This\n",
       "      parameter is only supported for `gpt-image-1`. Must be one of `transparent`,\n",
       "      `opaque` or `auto` (default value). When `auto` is used, the model will\n",
       "      automatically determine the best background for the image.\n",
       "\n",
       "      If `transparent`, the output format needs to support transparency, so it should\n",
       "      be set to either `png` (default value) or `webp`.\n",
       "\n",
       "  model: The model to use for image generation. One of `dall-e-2`, `dall-e-3`, or\n",
       "      `gpt-image-1`. Defaults to `dall-e-2` unless a parameter specific to\n",
       "      `gpt-image-1` is used.\n",
       "\n",
       "  moderation: Control the content-moderation level for images generated by `gpt-image-1`. Must\n",
       "      be either `low` for less restrictive filtering or `auto` (default value).\n",
       "\n",
       "  n: The number of images to generate. Must be between 1 and 10. For `dall-e-3`, only\n",
       "      `n=1` is supported.\n",
       "\n",
       "  output_compression: The compression level (0-100%) for the generated images. This parameter is only\n",
       "      supported for `gpt-image-1` with the `webp` or `jpeg` output formats, and\n",
       "      defaults to 100.\n",
       "\n",
       "  output_format: The format in which the generated images are returned. This parameter is only\n",
       "      supported for `gpt-image-1`. Must be one of `png`, `jpeg`, or `webp`.\n",
       "\n",
       "  quality: The quality of the image that will be generated.\n",
       "\n",
       "      - `auto` (default value) will automatically select the best quality for the\n",
       "        given model.\n",
       "      - `high`, `medium` and `low` are supported for `gpt-image-1`.\n",
       "      - `hd` and `standard` are supported for `dall-e-3`.\n",
       "      - `standard` is the only option for `dall-e-2`.\n",
       "\n",
       "  response_format: The format in which generated images with `dall-e-2` and `dall-e-3` are\n",
       "      returned. Must be one of `url` or `b64_json`. URLs are only valid for 60 minutes\n",
       "      after the image has been generated. This parameter isn't supported for\n",
       "      `gpt-image-1` which will always return base64-encoded images.\n",
       "\n",
       "  size: The size of the generated images. Must be one of `1024x1024`, `1536x1024`\n",
       "      (landscape), `1024x1536` (portrait), or `auto` (default value) for\n",
       "      `gpt-image-1`, one of `256x256`, `512x512`, or `1024x1024` for `dall-e-2`, and\n",
       "      one of `1024x1024`, `1792x1024`, or `1024x1792` for `dall-e-3`.\n",
       "\n",
       "  style: The style of the generated images. This parameter is only supported for\n",
       "      `dall-e-3`. Must be one of `vivid` or `natural`. Vivid causes the model to lean\n",
       "      towards generating hyper-real and dramatic images. Natural causes the model to\n",
       "      produce more natural, less hyper-real looking images.\n",
       "\n",
       "  user: A unique identifier representing your end-user, which can help OpenAI to monitor\n",
       "      and detect abuse.\n",
       "      [Learn more](https://platform.openai.com/docs/guides/safety-best-practices#end-user-ids).\n",
       "\n",
       "  extra_headers: Send extra headers\n",
       "\n",
       "  extra_query: Add additional query parameters to the request\n",
       "\n",
       "  extra_body: Add additional JSON properties to the request\n",
       "\n",
       "  timeout: Override the client-level default timeout for this request, in seconds\n",
       "\u001b[31mFile:\u001b[39m      ~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/resources/images.py\n",
       "\u001b[31mType:\u001b[39m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "client.images.generate(\n",
    "    prompt: 'str',\n",
    "    background = \"white\",\n",
    "    model= 'gpt-image-1',\n",
    "    # moderation: \"Optional[Literal['low', 'auto']] | NotGiven\" = NOT_GIVEN,\n",
    "    n=1,\n",
    "    output_format= \"jpeg\",\n",
    "    quality='low',\n",
    "    response_format='b64_json',\n",
    "    size='1024x1024',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e00eda-e9cf-45a4-8a11-80b891fa3657",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 500 - {'error': {'message': 'An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. Please include the request ID req_b00a91f56c55ef97bf1c6517980bdaf8 in your message.', 'type': 'server_error', 'param': None, 'code': 'server_error'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-image-1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgenerate a small image of a rabbit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/_utils/_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/resources/responses/responses.py:671\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, input, model, include, instructions, max_output_tokens, metadata, parallel_tool_calls, previous_response_id, reasoning, service_tier, store, stream, temperature, text, tool_choice, tools, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    641\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    642\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    643\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    669\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    670\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agent/lib/python3.11/site-packages/openai/_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 500 - {'error': {'message': 'An error occurred while processing your request. You can retry your request, or contact us through our help center at help.openai.com if the error persists. Please include the request ID req_b00a91f56c55ef97bf1c6517980bdaf8 in your message.', 'type': 'server_error', 'param': None, 'code': 'server_error'}}"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model= \"gpt-image-1\",\n",
    "    input=[{\"role\":\"user\",\"content\":\"generate a small image of a rabbit\"}],\n",
    "    store=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0259043d-1aeb-461d-b3be-d0d8b06effba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Giraffe',\n",
       " [{'name': 'body outline',\n",
       "   'stroke': \"'x15y25', 'x20y27', 'x30y27', 'x35y25', 'x35y20', 'x30y15', 'x20y15', 'x15y20', 'x15y25'\"},\n",
       "  {'name': 'neck', 'stroke': \"'x20y25', 'x22y35', 'x24y45', 'x25y45'\"},\n",
       "  {'name': 'head',\n",
       "   'stroke': \"'x25y45', 'x27y47', 'x29y46', 'x28y44', 'x25y45'\"},\n",
       "  {'name': 'ear', 'stroke': \"'x28y46', 'x30y47', 'x31y46'\"},\n",
       "  {'name': 'front left leg', 'stroke': \"'x18y15', 'x18y5'\"},\n",
       "  {'name': 'front right leg', 'stroke': \"'x25y15', 'x25y5'\"},\n",
       "  {'name': 'back right leg', 'stroke': \"'x30y15', 'x30y5'\"},\n",
       "  {'name': 'tail', 'stroke': \"'x35y20', 'x37y15', 'x38y10'\"},\n",
       "  {'name': 'eye', 'stroke': \"'x27y45'\"},\n",
       "  {'name': 'nostril', 'stroke': \"'x29y45'\"},\n",
       "  {'name': 'spot1', 'stroke': \"'x18y24'\"},\n",
       "  {'name': 'spot2', 'stroke': \"'x25y26'\"},\n",
       "  {'name': 'spot3', 'stroke': \"'x32y23'\"},\n",
       "  {'name': 'spot4', 'stroke': \"'x22y18'\"},\n",
       "  {'name': 'spot5', 'stroke': \"'x28y20'\"},\n",
       "  {'name': 'spot6', 'stroke': \"'x21y30'\"},\n",
       "  {'name': 'spot7', 'stroke': \"'x23y38'\"}])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import xmltodict\n",
    "\n",
    "def extract_xml(text: str, tag: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the content of the specified XML tag from the given text. Used for parsing structured responses \n",
    "\n",
    "    Args:\n",
    "        text (str): The text containing the XML.\n",
    "        tag (str): The XML tag to extract content from.\n",
    "\n",
    "    Returns:\n",
    "        str: The content of the specified XML tag, or an empty string if the tag is not found.\n",
    "    \"\"\"\n",
    "    match = re.search(f'<{tag}>(.*?)</{tag}>', text, re.DOTALL)\n",
    "    return f'<{tag}>{match.group(1)}</{tag}>' if match else \"\"\n",
    "\n",
    "def load_tutorial(path):\n",
    "    with open(path) as f:\n",
    "        txt_response = json.load(f)[2][\"content\"][0][\"text\"]\n",
    "\n",
    "    answer = extract_xml(txt_response+\"</answer>\",\"answer\")\n",
    "    answer_dict = xmltodict.parse(answer)\n",
    "    concept = answer_dict[\"answer\"][\"concept\"]\n",
    "    strokes = answer_dict[\"answer\"][\"strokes\"]\n",
    "    tutorial = [{\"name\": el['id'],\"stroke\":el[\"points\"]} for el in strokes.values()]\n",
    "    return concept, tutorial\n",
    "\n",
    "load_tutorial(\"/home/mos/exercises/SketchAgent/results/test/giraffe/experiment_log.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8b1ca7-6fd3-4470-8a89-ed0c0426947b",
   "metadata": {},
   "outputs": [],
   "source": [
    " gen_sketch.py --concept_to_draw giraffe\n",
    "/home/mos/exercises/SketchAgent/ge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent",
   "language": "python",
   "name": "agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
